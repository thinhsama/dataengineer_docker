# Weather ETL Project

## 1Ô∏è‚É£ Gi·ªõi thi·ªáu
D·ª± √°n **Weather ETL** s·ª≠ d·ª•ng **Apache Spark** ƒë·ªÉ x·ª≠ l√Ω v√† l∆∞u tr·ªØ d·ªØ li·ªáu th·ªùi ti·∫øt v√†o **PostgreSQL**. D·ªØ li·ªáu ƒë∆∞·ª£c l·∫•y t·ª´ m·ªôt t·∫≠p tin CSV ho·∫∑c c√≥ th·ªÉ m·ªü r·ªông ƒë·ªÉ l·∫•y t·ª´ API th·ªùi ti·∫øt.

D·ª± √°n bao g·ªìm:
- **Docker Compose** ƒë·ªÉ ch·∫°y Spark v√† PostgreSQL.
- **ETL Pipeline** ƒë·ªÉ ƒë·ªçc, x·ª≠ l√Ω v√† l∆∞u d·ªØ li·ªáu v√†o PostgreSQL.
- **Ph√¢n c·ª•m d·ªØ li·ªáu th·ªùi ti·∫øt b·∫±ng K-Means** v·ªõi Spark MLlib.

---

## 2Ô∏è‚É£ C√°ch c√†i ƒë·∫∑t v√† ch·∫°y d·ª± √°n

### **B∆∞·ªõc 1: C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng Docker v√† PySpark**

1. **T·∫°o v√† k√≠ch ho·∫°t virtual environment (n·∫øu c·∫ßn)**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   ```

2. **Ch·∫°y Docker Compose ƒë·ªÉ kh·ªüi ƒë·ªông Spark v√† PostgreSQL**:
   ```bash
   docker-compose up -d
   ```

3. **C√†i ƒë·∫∑t PySpark trong container**:
   ```bash
   docker exec -it spark-master bash
   pip install pyspark
   exit
   ```

---

### **B∆∞·ªõc 2: Chu·∫©n b·ªã d·ªØ li·ªáu**
1. **Ki·ªÉm tra t·∫≠p tin d·ªØ li·ªáu CSV c√≥ t·ªìn t·∫°i kh√¥ng**:
   ```python
   import os
   csv_path = "/opt/bitnami/spark/weather_data.csv"
   if not os.path.exists(csv_path):
       print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {csv_path}")
   ```
2. **Copy file CSV v√†o container**:
   ```bash
   docker cp weather_data.csv spark-master:/opt/bitnami/spark/weather_data.csv
   ```
3. **Ki·ªÉm tra file trong container**:
   ```bash
   docker exec -it spark-master ls /opt/bitnami/spark
   ```

---

### **B∆∞·ªõc 3: C·∫•u h√¨nh Spark ƒë·ªÉ k·∫øt n·ªëi PostgreSQL**
1. **C√†i ƒë·∫∑t JDBC driver trong container**:
   ```bash
   curl -o postgresql-42.2.20.jar https://repo1.maven.org/maven2/org/postgresql/postgresql/42.2.20.jar
   docker cp postgresql-42.2.20.jar spark-master:/opt/bitnami/spark/jars/
   ```
2. **X√°c minh driver ƒë√£ ƒë∆∞·ª£c th√™m v√†o Spark**:
   ```bash
   docker exec -it spark-master ls -l /opt/bitnami/spark/jars/postgresql-42.2.20.jar
   ```

---

### **B∆∞·ªõc 4: Ch·∫°y script ETL ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu**
1. **Copy script ETL v√†o container**:
   ```bash
   docker cp weather_etl.py spark-master:/weather_etl.py
   ```
2. **Ch·∫°y Spark script trong container**:
   ```bash
   docker exec -it spark-master bash -c "spark-submit /weather_etl.py"
   ```

---

### **B∆∞·ªõc 5: Ki·ªÉm tra d·ªØ li·ªáu trong PostgreSQL**
1. **Ki·ªÉm tra k·∫øt n·ªëi PostgreSQL**:
   ```bash
   docker exec -it postgres-db psql -U admin -d weather_db -c "SELECT 1;"
   ```
2. **Xem danh s√°ch c√°c b·∫£ng trong PostgreSQL**:
   ```sql
   SELECT table_name FROM information_schema.tables WHERE table_schema = 'public';
   ```
3. **Ki·ªÉm tra d·ªØ li·ªáu trong b·∫£ng `weather`**:
   ```sql
   SELECT * FROM weather LIMIT 5;
   ```

---

## 3Ô∏è‚É£ L·ªói th∆∞·ªùng g·∫∑p v√† c√°ch kh·∫Øc ph·ª•c

### ‚ùå **1. L·ªói Py4J: Kh√¥ng t√¨m th·∫•y JDBC driver**
**C√°ch kh·∫Øc ph·ª•c:** ƒê·∫£m b·∫£o ƒë√£ t·∫£i v·ªÅ **postgresql-42.2.20.jar** v√† copy v√†o ƒë√∫ng th∆∞ m·ª•c:
```bash
docker cp postgresql-42.2.20.jar spark-master:/opt/bitnami/spark/jars/
```

### ‚ùå **2. L·ªói k·∫øt n·ªëi PostgreSQL: `password authentication failed`**
**C√°ch kh·∫Øc ph·ª•c:**
- Ki·ªÉm tra l·∫°i t√†i kho·∫£n PostgreSQL:
  ```bash
  docker exec -it postgres-db psql -U admin -d postgres
  SELECT usename FROM pg_user;
  ```
- ƒê·∫£m b·∫£o URL k·∫øt n·ªëi ƒë√∫ng trong `weather_etl.py`:
  ```python
  postgres_url = "jdbc:postgresql://postgres-db:5432/weather_db"
  postgres_properties = {
      "user": "admin",
      "password": "123456",
      "driver": "org.postgresql.Driver"
  }
  ```

### ‚ùå **3. L·ªói file CSV kh√¥ng t·ªìn t·∫°i**
**C√°ch kh·∫Øc ph·ª•c:** Copy l·∫°i file v√†o container:
```bash
docker cp weather_data.csv spark-master:/opt/bitnami/spark/weather_data.csv
```

### ‚ùå **4. L·ªói b·∫£ng kh√¥ng t·ªìn t·∫°i trong PostgreSQL**
**C√°ch kh·∫Øc ph·ª•c:** Ki·ªÉm tra xem b·∫£ng ƒë√£ ƒë∆∞·ª£c t·∫°o ch∆∞a:
```sql
SELECT table_name FROM information_schema.tables WHERE table_schema = 'public';
```
N·∫øu kh√¥ng c√≥ b·∫£ng `weather`, ch·∫°y l·∫°i ETL script.

### ‚ùå **5. D·ªØ li·ªáu NULL sau khi chuy·ªÉn ƒë·ªïi**
**C√°ch kh·∫Øc ph·ª•c:**
- Ki·ªÉm tra d·ªØ li·ªáu g·ªëc t·ª´ CSV:
  ```bash
  docker exec -it spark-master bash -c "cat /opt/bitnami/spark/weather_data.csv"
  ```
- Ki·ªÉm tra schema sau khi ƒë·ªçc:
  ```python
  df.printSchema()
  ```

---

## 4Ô∏è‚É£ T√≠ch h·ª£p Ph√¢n C·ª•m D·ªØ Li·ªáu v·ªõi Spark MLlib
Sau khi ETL xong, ta c√≥ th·ªÉ ph√¢n c·ª•m d·ªØ li·ªáu b·∫±ng **K-Means Clustering** ƒë·ªÉ t√¨m **c√°c nh√≥m th·ªùi ti·∫øt t∆∞∆°ng t·ª± nhau**.

### **üìå B∆∞·ªõc 1: Ch·∫°y script ph√¢n c·ª•m**
```bash
docker exec -it spark-master bash -c "spark-submit /weather_clustering.py"
```

### **üìå B∆∞·ªõc 2: Ki·ªÉm tra k·∫øt qu·∫£ ph√¢n c·ª•m**
```sql
SELECT * FROM weather_clusters;
```
B·∫£ng s·∫Ω ch·ª©a c·ªôt `prediction`, cho bi·∫øt m·ªói b·∫£n ghi thu·ªôc c·ª•m n√†o.

---

## 5Ô∏è‚É£ T·ªïng k·∫øt
- **Docker gi√∫p d·ªÖ d√†ng tri·ªÉn khai Spark v√† PostgreSQL** m√† kh√¥ng c·∫ßn c√†i ƒë·∫∑t nhi·ªÅu.
- **Spark gi√∫p x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn v√† ch·∫°y m√¥ h√¨nh machine learning**.
- **PostgreSQL l√† n∆°i l∆∞u tr·ªØ d·ªØ li·ªáu** ƒë·ªÉ d·ªÖ d√†ng truy v·∫•n v√† ph√¢n t√≠ch.

D·ª± √°n n√†y c√≥ th·ªÉ m·ªü r·ªông b·∫±ng c√°ch:
- **Thu th·∫≠p d·ªØ li·ªáu t·ª± ƒë·ªông t·ª´ API** thay v√¨ CSV.
- **D·ª± b√°o xu h∆∞·ªõng th·ªùi ti·∫øt** b·∫±ng c√°c m√¥ h√¨nh machine learning kh√°c.

üî• **Ch·∫°y th·ª≠ ngay v√† m·ªü r·ªông d·ª± √°n c·ªßa b·∫°n!** üöÄ

